{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1137fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:14:58.390019Z",
     "iopub.status.busy": "2023-10-15T12:14:58.389651Z",
     "iopub.status.idle": "2023-10-15T12:16:33.084288Z",
     "shell.execute_reply": "2023-10-15T12:16:33.083151Z"
    },
    "papermill": {
     "duration": 94.702845,
     "end_time": "2023-10-15T12:16:33.086601",
     "exception": false,
     "start_time": "2023-10-15T12:14:58.383756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dicomsdl--0-109-2/dicomsdl-0.109.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Installing collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.2\r\n",
      "Processing /kaggle/input/contrails-libraries/segmentation_models_pytorch-0.3.3-py3-none-any.whl\r\n",
      "Installing collected packages: segmentation-models-pytorch\r\n",
      "Successfully installed segmentation-models-pytorch-0.3.3\r\n",
      "Processing /kaggle/input/contrails-model-def1/einops-0.6.1-py3-none-any.whl\r\n",
      "Installing collected packages: einops\r\n",
      "Successfully installed einops-0.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/dicomsdl--0-109-2/dicomsdl-0.109.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "\n",
    "import sys\n",
    "!cp -r '/kaggle/input/contrails-libraries/pretrainedmodels-0.7.4/' './'\n",
    "#!pip install './pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/'\n",
    "sys.path.append('./pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/')\n",
    "\n",
    "!cp -r '/kaggle/input/contrails-libraries/efficientnet_pytorch-0.7.1/' './'\n",
    "#!pip install './efficientnet_pytorch-0.7.1/efficientnet_pytorch-0.7.1/'\n",
    "sys.path.append('./efficientnet_pytorch-0.7.1/efficientnet_pytorch-0.7.1/')\n",
    "\n",
    "!pip install '/kaggle/input/contrails-libraries/segmentation_models_pytorch-0.3.3-py3-none-any.whl' --no-deps\n",
    "\n",
    "!pip install /kaggle/input/contrails-model-def1/einops-0.6.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb2d19",
   "metadata": {
    "papermill": {
     "duration": 0.003827,
     "end_time": "2023-10-15T12:16:33.094796",
     "exception": false,
     "start_time": "2023-10-15T12:16:33.090969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76103c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:16:33.104814Z",
     "iopub.status.busy": "2023-10-15T12:16:33.104535Z",
     "iopub.status.idle": "2023-10-15T12:16:33.122973Z",
     "shell.execute_reply": "2023-10-15T12:16:33.122161Z"
    },
    "papermill": {
     "duration": 0.026124,
     "end_time": "2023-10-15T12:16:33.124821",
     "exception": false,
     "start_time": "2023-10-15T12:16:33.098697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp.py\n",
    "\n",
    "import sys\n",
    "#!pip install './pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/'\n",
    "sys.path.append('./pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/')\n",
    "\n",
    "#!pip install './efficientnet_pytorch-0.7.1/efficientnet_pytorch-0.7.1/'\n",
    "sys.path.append('./efficientnet_pytorch-0.7.1/efficientnet_pytorch-0.7.1/')\n",
    "\n",
    "import dicomsdl\n",
    "def __dataset__to_numpy_image(self, index=0):\n",
    "    info = self.getPixelDataInfo()\n",
    "    dtype = info['dtype']\n",
    "    if info['SamplesPerPixel'] != 1:\n",
    "        raise RuntimeError('SamplesPerPixel != 1')\n",
    "    else:\n",
    "        shape = [info['Rows'], info['Cols']]\n",
    "    outarr = np.empty(shape, dtype=dtype)\n",
    "    self.copyFrameData(index, outarr)\n",
    "    return outarr\n",
    "dicomsdl._dicomsdl.DataSet.to_numpy_image = __dataset__to_numpy_image   \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os, copy, time\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import pydicom\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "sys.path.append(\"/kaggle/input/rsna-abd-models-classes/\")\n",
    "from models import *\n",
    "\n",
    "\n",
    "local_rank = int(os.environ['LOCAL_RANK'])\n",
    "torch.cuda.set_device(local_rank)\n",
    "\n",
    "\n",
    "def glob_sorted(path):\n",
    "    return sorted(glob(path), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "def get_rescaled_image(dcm, img):\n",
    "    resI, resS = dcm.RescaleIntercept, dcm.RescaleSlope\n",
    "    \n",
    "    img = resS * img + resI\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_windowed_image(img, WL=50, WW=400):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "    \n",
    "    return X\n",
    "\n",
    "def standardize_pixel_array(dcm, pixel_array):\n",
    "    \"\"\"\n",
    "    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n",
    "    \"\"\"\n",
    "    # Correct DICOM pixel_array if PixelRepresentation == 1.\n",
    "    #pixel_array = dcm.pixel_array\n",
    "    \n",
    "    if dcm.PixelRepresentation == 1:\n",
    "        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n",
    "        dtype = pixel_array.dtype \n",
    "        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n",
    "#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n",
    "\n",
    "    intercept = float(dcm.RescaleIntercept)\n",
    "    slope = float(dcm.RescaleSlope)\n",
    "    center = int(dcm.WindowCenter)\n",
    "    width = int(dcm.WindowWidth)\n",
    "    low = center - width / 2\n",
    "    high = center + width / 2    \n",
    "    \n",
    "    pixel_array = (pixel_array * slope) + intercept\n",
    "    pixel_array = np.clip(pixel_array, low, high)\n",
    "\n",
    "    return pixel_array\n",
    "\n",
    "def load_volume(dcms):\n",
    "    volume = []\n",
    "    file_to_volume_theo = {}\n",
    "    pos_zs = []\n",
    "    \n",
    "    for dcm_path in dcms:\n",
    "        pydcm = pydicom.dcmread(dcm_path)\n",
    "        #image = dcm.pixel_array\n",
    "        \n",
    "        pos_z = pydcm[(0x20, 0x32)].value[-1]\n",
    "        pos_zs.append(pos_z)\n",
    "        \n",
    "        dcm = dicomsdl.open(dcm_path)\n",
    "        \n",
    "        orig_image = dcm.to_numpy_image()\n",
    "        \n",
    "        image = get_rescaled_image(dcm, orig_image)\n",
    "        image = get_windowed_image(image)\n",
    "        \n",
    "        image2 = standardize_pixel_array(dcm, orig_image)\n",
    "        image2 = (image2 - image2.min()) / (image2.max() - image2.min() + 1e-6)\n",
    "        \n",
    "        if pydcm.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            image2 = 1 - image2\n",
    "        \n",
    "        image2 = (image2 * 255).astype(np.uint8)\n",
    "        \n",
    "        file_to_volume_theo[dcm_path] = image2\n",
    "        \n",
    "        #image = get_windowed_image(dcm)\n",
    "        \n",
    "        if np.min(image)<0:\n",
    "            image = image + np.abs(np.min(image))\n",
    "        \n",
    "        image = image / image.max()\n",
    "        \n",
    "        \n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        volume.append(image)\n",
    "    \n",
    "    idxs = np.argsort(pos_zs)\n",
    "    files_theo = np.array(dcms)[idxs]\n",
    "    \n",
    "    return np.stack(volume), file_to_volume_theo, files_theo\n",
    "\n",
    "\n",
    "def load_volume_theo(dcms):\n",
    "    volume = []\n",
    "    imgs = {}\n",
    "    for dcm_path in dcms:\n",
    "        dicom = pydicom.dcmread(dcm_path)\n",
    "\n",
    "        pos_z = dicom[(0x20, 0x32)].value[-1]\n",
    "        \n",
    "        dcm = dicomsdl.open(dcm_path)\n",
    "        img = standardize_pixel_array(dcm)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "        \n",
    "        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            img = 1 - img\n",
    "        \n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        \n",
    "        imgs[pos_z] = img\n",
    "    \n",
    "    for i, k in enumerate(sorted(imgs.keys())):\n",
    "        img = imgs[k]\n",
    "        \n",
    "        volume.append(img)\n",
    "    \n",
    "    return np.stack(volume), np.array(dcms)[np.argsort(list(imgs.keys()))]\n",
    "\n",
    "def process_volume(volume):\n",
    "    volume = np.stack([cv2.resize(x, (128, 128)) for x in volume])\n",
    "    \n",
    "    volumes = []\n",
    "    cuts = [(x, x+32) for x in np.arange(0, volume.shape[0], 32)[:-1]]\n",
    "    \n",
    "    if cuts:\n",
    "        for cut in cuts:\n",
    "            volumes.append(volume[cut[0]:cut[1]])\n",
    "            \n",
    "        volumes = np.stack(volumes)\n",
    "    else:\n",
    "        volumes = np.zeros((1, 32, 128, 128), dtype=np.uint8)\n",
    "        volumes[0, :len(volume)] = volume\n",
    "    \n",
    "    if cuts:\n",
    "        last_volume = np.zeros((1, 32, 128, 128), dtype=np.uint8)\n",
    "        last_volume[0, :volume[cuts[-1][1]:].shape[0]] =  volume[cuts[-1][1]:]\n",
    "    \n",
    "        volumes = np.concatenate([volumes, last_volume])\n",
    "    \n",
    "    volumes = torch.as_tensor(volumes).float()\n",
    "    \n",
    "    return volumes\n",
    "\n",
    "def get_volume_data(grd, step=96, stride=1, stride_cutoff=200):\n",
    "    volumes = []\n",
    "    \n",
    "    if len(grd)>stride_cutoff:\n",
    "        grd = grd[::stride]\n",
    "\n",
    "    take_last = False\n",
    "    if not str(len(grd)/step).endswith('.0'):\n",
    "        take_last = True\n",
    "\n",
    "    started = False\n",
    "    for i in range(len(grd)//step):\n",
    "        rows = grd[i*step:(i+1)*step]\n",
    "\n",
    "        if len(rows)!=step:\n",
    "            rows = pd.DataFrame([rows.iloc[int(x*len(rows))] for x in np.arange(0, 1, 1/step)])\n",
    "\n",
    "        volumes.append(rows)\n",
    "\n",
    "        started = True\n",
    "\n",
    "    if not started:\n",
    "        rows = grd\n",
    "        rows = pd.DataFrame([rows.iloc[int(x*len(rows))] for x in np.arange(0, 1, 1/step)])\n",
    "        volumes.append(rows)\n",
    "\n",
    "    if take_last:\n",
    "        rows = grd[-step:]\n",
    "        if len(rows)==step:\n",
    "            volumes.append(rows)\n",
    "\n",
    "    return volumes\n",
    "\n",
    "\n",
    "\n",
    "IMAGE_FOLDER = '/kaggle/input/rsna-2023-abdominal-trauma-detection/test_images/'\n",
    "\n",
    "test_patients = np.array(os.listdir(IMAGE_FOLDER))\n",
    "\n",
    "DEBUG = False\n",
    "if len(test_patients)<10:\n",
    "    DEBUG = True\n",
    "    IMAGE_FOLDER = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/'\n",
    "\n",
    "test_patients = np.array(os.listdir(IMAGE_FOLDER))\n",
    "\n",
    "test_augs = A.Compose([\n",
    "    A.Resize(384, 384),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_augs2 = A.Compose([\n",
    "    A.Resize(384, 384),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "if DEBUG:\n",
    "    submission = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/sample_submission.csv')\n",
    "    \n",
    "test_patients, test_patients.shape\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "segmentation_models = []\n",
    "for F in [0]:\n",
    "    model = convert_3d(SegmentationModel())\n",
    "    state_dict = torch.load(f'/kaggle/input/rsna-abd-models/try3_seg_resnet18d_v3/zip/{F}.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    import copy\n",
    "    segmentation_models.append(copy.deepcopy(model))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outs = model(torch.zeros((2, 32, 128, 128)).cuda())\n",
    "_ = [print(o.shape) for o in outs]\n",
    "\n",
    "classification_models = []\n",
    "\n",
    "'''\n",
    "for F in [0, 1, 2]:\n",
    "    path = f\"/kaggle/input/coatlitemedium-384-exp1/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model4(num_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "for F in [1, 3]:\n",
    "    path = f\"/kaggle/input/coatmed-newseg-ourdata-4f/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model5(num_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "for F in range(1, 4):\n",
    "    path = f\"/kaggle/input/rsna-abd-models/try5_cls_tf_efficientnetv2_s_in21ft1k_v10/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model3(n_classes=10)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "for F in [3407, 69, 42, 17716124]:\n",
    "    path = f\"/kaggle/input/rsna-abd-models-2/try11_cls_tf_efficientnetv2_s_in21ft1k_v1_fulldata/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model3(n_classes=10)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "#'''\n",
    "\n",
    "#'''\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "for F in range(1):\n",
    "    path = f\"/kaggle/input/coatmed384ourdataseed100/3.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "\n",
    "    model = Model4(num_classes=10, seg_classes=4, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "\n",
    "for F in range(1):\n",
    "    path = f\"/kaggle/input/coatmed384ourdataseed6969/3.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "\n",
    "    model = Model4(num_classes=10, seg_classes=4, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "#for F in range(1):\n",
    "#    path = f\"/kaggle/input/coatmed384fullseed696969/3.pth\"\n",
    "#    st = torch.load(path, map_location='cpu')\n",
    "\n",
    "#    model = Model4(num_classes=10, seg_classes=4, arch='medium', mask_head=False)\n",
    "#    model.load_state_dict(st)\n",
    "#    model.cuda()\n",
    "#    model.eval()\n",
    "\n",
    "#    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "for F in range(1):\n",
    "    path = f\"/kaggle/input/coatmed384fullseed969696/3.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "\n",
    "    model = Model4(num_classes=10, seg_classes=4, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "for F in [1]:\n",
    "    path = f\"/kaggle/input/coatmed-newseg-ourdata-4f/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model5(num_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "\n",
    "    \n",
    "for F in [2]:\n",
    "    path = f\"/kaggle/input/coatlitemedium-384-exp1/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model4(num_classes=10, seg_classes=3, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "\n",
    "    \n",
    "for F in [123123, 123123123]:\n",
    "    path = f\"/kaggle/input/rsna-abd-v2s-try5-v10-fulldata/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model3(n_classes=10)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "for F in [7]:\n",
    "    path = f\"/kaggle/input/coat-lite-medium-bs2-lr9e5-seed7/0.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model5(n_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "\n",
    "for F in [7777]:\n",
    "    path = f\"/kaggle/input/coat-lite-medium-bs2-lr10e5-seed7777/0.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model5(n_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "\n",
    "for F in [7777777]:\n",
    "    path = f\"/kaggle/input/coat-lite-medium-bs2-lr11e5-seed7777777/0.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model5(n_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "#for F in [42]:\n",
    "#    path = f\"/kaggle/input/coat-lite-medium-bs2-lr12e5-seed42/0.pth\"\n",
    "#    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "#    model = Model5(n_classes=10, arch='medium', mask_head=False)\n",
    "#    model.load_state_dict(st)\n",
    "#    model.cuda()\n",
    "#    model.eval()\n",
    "\n",
    "#    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "for F in [0]:\n",
    "    path = f\"/kaggle/input/coat-lite-medium-bs2-lr125e6/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model5(num_classes=10, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "\n",
    "    \n",
    "for F in [3]:\n",
    "    path = f\"/kaggle/input/coat-lite-medium-unet-bs1-lr10e5-seed7777/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model7(num_classes=4, arch='medium', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "    \n",
    "for F in [69, 17716124]:\n",
    "    path = f\"/kaggle/input/rsna-abd-models-2/try11_cls_tf_efficientnetv2_s_in21ft1k_v1_fulldata/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "   \n",
    "    model = Model3(n_classes=10)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    classification_models.append(copy.deepcopy(model))\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "print(len(classification_models))\n",
    "\n",
    "\n",
    "\n",
    "extra_models = []\n",
    "\n",
    "for F in [0,1,2, 3]:\n",
    "    path = f\"/kaggle/input/coatsmall384extravast4funet/{F}.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model4(num_classes=2, seg_classes=4, arch='small', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    extra_models.append(copy.deepcopy(model))\n",
    "    \n",
    "    #break\n",
    "for F in [2024]:\n",
    "    path = f\"/kaggle/input/fullextracoatsmall384/3_best.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model4(num_classes=2, seg_classes=4, arch='small', mask_head=False)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    extra_models.append(copy.deepcopy(model))\n",
    "    \n",
    "# for F in [2717]:\n",
    "#     path = f\"/kaggle/input/fullextracoatsmall384/2_best.pth\"\n",
    "#     st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "#     model = Model4(num_classes=2, seg_classes=4, arch='small', mask_head=False)\n",
    "#     model.load_state_dict(st)\n",
    "#     model.cuda()\n",
    "#     model.eval()\n",
    "    \n",
    "#     extra_models.append(copy.deepcopy(model))  \n",
    "    \n",
    "    \n",
    "print(len(extra_models))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now this is a list only for name\n",
    "extra_models_theo_newseg = []\n",
    "\n",
    "for F in [0,1,2,3]:\n",
    "    path = f\"/kaggle/input/rsna-abd-try11-v8-extrav/{F}_best.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model6(n_classes=2)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    extra_models_theo_newseg.append(copy.deepcopy(model))\n",
    "    \n",
    "    #break\n",
    "\n",
    "for F in [0, 2]:\n",
    "    path = f\"/kaggle/input/coatmedium384extravast/{F}_best.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model5(n_classes=2)\n",
    "    model.head = nn.Sequential(\n",
    "            #nn.Linear(lstm_embed, lstm_embed//2),\n",
    "            #nn.BatchNorm1d(lstm_embed//2),\n",
    "            nn.Dropout(0.1),\n",
    "            #nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512*2, 2),\n",
    "        )\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    extra_models_theo_newseg.append(copy.deepcopy(model))\n",
    "    \n",
    "#     extra_models_theo_newseg.append(copy.deepcopy(model))\n",
    "    \n",
    "'''\n",
    "for F in range(4):\n",
    "    path = f\"/kaggle/input/rsna-abd-coat-small-extrav/{F}_best.pth\"\n",
    "    st = torch.load(path, map_location='cpu')\n",
    "    \n",
    "    model = Model6(n_classes=2)\n",
    "    model.load_state_dict(st)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    extra_models_theo_newseg.append(copy.deepcopy(model))\n",
    "    \n",
    "    #break\n",
    "'''\n",
    "\n",
    "print('theo extra:, ', len(extra_models_theo_newseg))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "PATIENT_TO_PREDICTION = {}\n",
    "PATIENT_TO_PREDICTION2 = {}\n",
    "\n",
    "#if local_rank==0:\n",
    "#    test_patients = [58359,]\n",
    "#else:\n",
    "#    test_patients = [31966]\n",
    "\n",
    "PATIENT_TO_PREDICTION = {}\n",
    "PATIENT_TO_PREDICTION2 = {}\n",
    "PATIENT_TO_PREDICTION_THEO = {}\n",
    "PATIENT_TO_PREDICTION4 = {}\n",
    "\n",
    "\n",
    "if local_rank==0:\n",
    "    test_patients = test_patients[:len(test_patients)//2]\n",
    "    #test_patients = test_patients[:5]\n",
    "else:\n",
    "    test_patients = test_patients[len(test_patients)//2:]\n",
    "    #test_patients = test_patients[:10]\n",
    "\n",
    "\n",
    "for patient in tqdm(test_patients):\n",
    "#for patient in tqdm(test_patients[1+local_rank:]):\n",
    "    try:\n",
    "    #if 1:\n",
    "\n",
    "        studies = os.listdir(f'{IMAGE_FOLDER}/{patient}')\n",
    "\n",
    "        final_outputs = []\n",
    "        final_outputs2 = []\n",
    "        final_outputs3 = []\n",
    "        final_outputs4 = []\n",
    "        for study in studies:\n",
    "\n",
    "            files = glob_sorted(f\"{IMAGE_FOLDER}/{patient}/{study}/*\")\n",
    "\n",
    "            #volume = load_volume(files)\n",
    "            #volume_theo, files_theo = load_volume_theo(files)\n",
    "            \n",
    "            volume, file_to_volume_theo, files_theo = load_volume(files)\n",
    "            \n",
    "            file_to_volume = {file: vol for file, vol in zip(files, volume)}\n",
    "\n",
    "            volumes = process_volume(volume)\n",
    "            volumes_seg = predict_segmentation(volumes, segmentation_models)\n",
    "            volume_seg = np.concatenate(volumes_seg.transpose(0, 2, 1, 3, 4))[:len(volume)]\n",
    "\n",
    "            msk = volume_seg.max(0).max(0)\n",
    "            ys, xs = np.where(msk)\n",
    "            #y1, y2, x1, x2 = np.min(ys) / 128, np.max(ys) / 128, np.min(xs) / 128, np.max(xs) / 128\n",
    "            y1, y2, x1, x2 = np.min(ys) / 128, np.max(ys) / 128, np.min(xs) / 128, np.max(xs) / 128\n",
    "    \n",
    "            files = pd.DataFrame({\"file\": files})\n",
    "            files_theo = pd.DataFrame({\"file\": files_theo})\n",
    "\n",
    "            files_volumes = get_volume_data(files, step=96, stride=2, stride_cutoff=400)\n",
    "            files_volumes_theo = get_volume_data(files_theo, step=96, stride=2, stride_cutoff=400)\n",
    "\n",
    "            first = True\n",
    "            \n",
    "            import gc\n",
    "            del volumes, volumes_seg, volume_seg, volume\n",
    "            gc.collect()\n",
    "\n",
    "            for file_volume, file_volume_theo in zip(files_volumes, files_volumes_theo):\n",
    "                #volume = load_volume(file_volume.file)\n",
    "                volume = np.stack([file_to_volume[file] for file in file_volume.file])\n",
    "                volume_theo = np.stack([file_to_volume_theo[file] for file in file_volume_theo.file])\n",
    "\n",
    "                if first:\n",
    "                    h, w = volume.shape[1:]\n",
    "                    y1, y2, x1, x2 = int(y1*h), int(y2*h), int(x1*w), int(x2*w)\n",
    "                volume2 = volume\n",
    "                volume_theo_uncrop = volume_theo\n",
    "                volume = volume[:, y1:y2, x1:x2]\n",
    "                \n",
    "                #----------------------------\n",
    "                #----------------------------\n",
    "                #MASSIVE CHANGE HERE, NOT CROPPPING THEO DATA BECAUSE ONLY USING IT FOR EXTRAVASATION, MAKE VOLUME_THEO_UNCROP SEPERATELY WHEN USING AT BOTH PLACES\n",
    "                volume_theo = volume_theo[:, y1:y2, x1:x2]\n",
    "                #----------------------------\n",
    "                #----------------------------\n",
    "                \n",
    "                #'''\n",
    "                vols = []\n",
    "                NC = 3\n",
    "                for i in range(len(volume)//NC):\n",
    "                    vols.append(volume[i*NC:(i+1)*NC])\n",
    "                vol = np.stack(vols, 0).transpose(0, 2, 3, 1)\n",
    "                \n",
    "                volume_ = []\n",
    "                for image in vol:\n",
    "\n",
    "                    #np.random.seed(CFG.literal_step)\n",
    "                    #random.seed(CFG.literal_step)\n",
    "                    \n",
    "                    image = image.astype(np.float32) / 255\n",
    "\n",
    "                    transformed = test_augs2(image=image)\n",
    "\n",
    "                    image = transformed['image']\n",
    "\n",
    "                    volume_.append(image)\n",
    "\n",
    "                volume = torch.stack(volume_).float()\n",
    "                volume = volume.cuda()\n",
    "                #'''\n",
    "                \n",
    "                #### UNCROPPED #####\n",
    "                vols = []\n",
    "                NC = 3\n",
    "                for i in range(len(volume2)//NC):\n",
    "                    vols.append(volume2[i*NC:(i+1)*NC])\n",
    "                vol = np.stack(vols, 0).transpose(0, 2, 3, 1)\n",
    "\n",
    "                volume_ = []\n",
    "                for image in vol:\n",
    "\n",
    "                    #np.random.seed(CFG.literal_step)\n",
    "                    #random.seed(CFG.literal_step)\n",
    "                    \n",
    "                    image = image.astype(np.float32) / 255\n",
    "\n",
    "                    transformed = test_augs(image=image)\n",
    "\n",
    "                    image = transformed['image']\n",
    "\n",
    "                    volume_.append(image)\n",
    "\n",
    "                volume2 = torch.stack(volume_).float()\n",
    "                volume2 = volume2.cuda()\n",
    "                \n",
    "                \n",
    "                outputs = []\n",
    "                outputs2 = []\n",
    "                outputs3 = []\n",
    "                outputs4 = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.amp.autocast(enabled=True):\n",
    "\n",
    "                        for model in classification_models[:7]:\n",
    "                            outs = model(volume.unsqueeze(0))\n",
    "                            outs = outs.float().sigmoid()\n",
    "                            outputs.append(outs)\n",
    "\n",
    "                        for model in extra_models:\n",
    "                            outs = model(volume2.unsqueeze(0))[:, :, [1, 0]]\n",
    "                            outs = outs.float().sigmoid()\n",
    "                            outputs2.append(outs)\n",
    "                        \n",
    "#                         for model in extra_models_theo_newseg[4:]:\n",
    "#                             outs = model(volume2.unsqueeze(0))[:, :, [1, 0]]\n",
    "#                             outs = outs.float().sigmoid()\n",
    "#                             outputs2.append(outs)\n",
    "                \n",
    "                \n",
    "                import gc\n",
    "                #del volume, volume2, volume_, vol, vols\n",
    "                del volume2, volume_, vol, vols\n",
    "                gc.collect()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                #### THEO DATA #####\n",
    "                vols = []\n",
    "                NC = 3\n",
    "                for i in range(len(volume_theo)//NC):\n",
    "                    vols.append(volume_theo[i*NC:(i+1)*NC])\n",
    "                vol = np.stack(vols, 0).transpose(0, 2, 3, 1)\n",
    "                \n",
    "                volume_ = []\n",
    "                for image in vol:\n",
    "                    #np.random.seed(CFG.literal_step)\n",
    "                    #random.seed(CFG.literal_step)\n",
    "                    \n",
    "                    image = image.astype(np.float32) / 255\n",
    "\n",
    "                    transformed = test_augs(image=image)\n",
    "                    image = transformed['image']\n",
    "\n",
    "                    volume_.append(image)\n",
    "\n",
    "                volume_theo = torch.stack(volume_).float()\n",
    "                volume_theo = volume_theo.cuda()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.amp.autocast(enabled=True):\n",
    "                        for model in classification_models[7:]:\n",
    "                            outs = model(volume_theo.unsqueeze(0))\n",
    "                            outs = outs.float().sigmoid()\n",
    "                            outputs3.append(outs)\n",
    "                \n",
    "                import gc\n",
    "                #del volume, volume2, volume_, vol, vols\n",
    "                del volume_, vol, vols\n",
    "                gc.collect()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                \n",
    "                #### THEO UNCROP DATA #####\n",
    "                vols = []\n",
    "                NC = 3\n",
    "                for i in range(len(volume_theo_uncrop)//NC):\n",
    "                    vols.append(volume_theo_uncrop[i*NC:(i+1)*NC])\n",
    "                vol = np.stack(vols, 0).transpose(0, 2, 3, 1)\n",
    "                \n",
    "                volume_ = []\n",
    "                for image in vol:\n",
    "                    #np.random.seed(CFG.literal_step)\n",
    "                    #random.seed(CFG.literal_step)\n",
    "                    \n",
    "                    image = image.astype(np.float32) / 255\n",
    "\n",
    "                    transformed = test_augs(image=image)\n",
    "                    image = transformed['image']\n",
    "\n",
    "                    volume_.append(image)\n",
    "\n",
    "                volume_theo = torch.stack(volume_).float()\n",
    "                volume_theo = volume_theo.cuda()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.amp.autocast(enabled=True):\n",
    "                        \n",
    "                        for model in extra_models_theo_newseg[:4]:\n",
    "                            outs = model(volume_theo.unsqueeze(0))\n",
    "                            outs = outs.float().sigmoid()\n",
    "                            outputs4.append(outs)\n",
    "                            \n",
    "                        for model in extra_models_theo_newseg[4:]:\n",
    "                            outs = model(volume_theo.unsqueeze(0))[:,:,[1,0]]\n",
    "                            outs = outs.float().sigmoid()\n",
    "                            outputs4.append(outs)\n",
    "                \n",
    "                \n",
    "                outputs = torch.stack(outputs)[:, 0].mean(0)\n",
    "                outputs2 = torch.stack(outputs2)[:, 0].mean(0)\n",
    "                outputs3 = torch.stack(outputs3)[:, 0].mean(0)\n",
    "                outputs4 = torch.stack(outputs4)[:, 0].mean(0)\n",
    "                \n",
    "                #outputs = (outputs * 0.5) + (outputs3 * 0.5)\n",
    "                #outputs = outputs3\n",
    "                \n",
    "                final_outputs.append(outputs.detach().cpu().numpy())\n",
    "                final_outputs2.append(outputs2.detach().cpu().numpy())\n",
    "                final_outputs3.append(outputs3.detach().cpu().numpy())\n",
    "                final_outputs4.append(outputs4.detach().cpu().numpy())\n",
    "\n",
    "                first = False\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "#               break\n",
    "    except:\n",
    "#     else:\n",
    "        final_outputs = last_final_outputs.copy()\n",
    "        final_outputs2 = last_final_outputs2.copy()\n",
    "        final_outputs3 = last_final_outputs3.copy()\n",
    "        final_outputs4 = last_final_outputs4.copy()\n",
    "    \n",
    "    last_final_outputs = final_outputs.copy()\n",
    "    last_final_outputs2 = final_outputs2.copy()\n",
    "    last_final_outputs3 = final_outputs3.copy()\n",
    "    last_final_outputs4 = final_outputs4.copy()\n",
    "\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "    final_outputs2 = np.concatenate(final_outputs2)\n",
    "    final_outputs3 = np.concatenate(final_outputs3)\n",
    "    final_outputs4 = np.concatenate(final_outputs4)\n",
    "\n",
    "    final_predictions = final_outputs.max(0)\n",
    "    final_predictions2 = final_outputs2.max(0)\n",
    "    final_predictions3 = final_outputs3.max(0)\n",
    "    final_predictions4 = final_outputs4.max(0)\n",
    "\n",
    "    PATIENT_TO_PREDICTION[patient] = final_predictions\n",
    "    PATIENT_TO_PREDICTION2[patient] = final_predictions2\n",
    "    PATIENT_TO_PREDICTION_THEO[patient] = final_predictions3\n",
    "    PATIENT_TO_PREDICTION4[patient] = final_predictions4\n",
    "\n",
    "    if DEBUG:\n",
    "        break\n",
    "        \n",
    "np.save(f'PATIENT_TO_PREDICTION_rank{local_rank}.npy', PATIENT_TO_PREDICTION)\n",
    "np.save(f'PATIENT_TO_PREDICTION2_rank{local_rank}.npy', PATIENT_TO_PREDICTION2)\n",
    "np.save(f'PATIENT_TO_PREDICTION_THEO_rank{local_rank}.npy', PATIENT_TO_PREDICTION_THEO)\n",
    "np.save(f'PATIENT_TO_PREDICTION4_rank{local_rank}.npy', PATIENT_TO_PREDICTION4)\n",
    "\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46889f21",
   "metadata": {
    "papermill": {
     "duration": 0.003696,
     "end_time": "2023-10-15T12:16:33.132235",
     "exception": false,
     "start_time": "2023-10-15T12:16:33.128539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2ab91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:16:33.141599Z",
     "iopub.status.busy": "2023-10-15T12:16:33.140788Z",
     "iopub.status.idle": "2023-10-15T12:19:34.023589Z",
     "shell.execute_reply": "2023-10-15T12:19:34.022274Z"
    },
    "papermill": {
     "duration": 180.890926,
     "end_time": "2023-10-15T12:19:34.027079",
     "exception": false,
     "start_time": "2023-10-15T12:16:33.136153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\r\n",
      "and will be removed in future. Use torchrun.\r\n",
      "Note that --use-env is set by default in torchrun.\r\n",
      "If your script expects `--local-rank` argument to be set, please\r\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \r\n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \r\n",
      "further instructions\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/kaggle/working/./pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:255: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\r\n",
      "  if block_type is 'proj':\r\n",
      "/kaggle/working/./pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:258: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\r\n",
      "  elif block_type is 'down':\r\n",
      "/kaggle/working/./pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\r\n",
      "  assert block_type is 'normal'\r\n",
      "torch.Size([5, 32, 128, 128])\r\n",
      "torch.Size([5, 32, 128, 128])\r\n",
      "torch.Size([5, 32, 128, 128])\r\n",
      "torch.Size([5, 32, 128, 128])\r\n",
      "14\r\n",
      "14\r\n",
      "5\r\n",
      "5\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "total channels in seg head:  160 256\r\n",
      "theo extra:,  6\r\n",
      "  0%|                                                  | 0/1574 [00:00<?, ?it/s]theo extra:,  6\r\n",
      "  0%|                                                  | 0/1573 [00:46<?, ?it/s]\r\n",
      "  0%|                                                  | 0/1574 [00:54<?, ?it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1, python -m torch.distributed.launch --nproc_per_node=2 ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b715a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:34.040295Z",
     "iopub.status.busy": "2023-10-15T12:19:34.039970Z",
     "iopub.status.idle": "2023-10-15T12:19:34.044284Z",
     "shell.execute_reply": "2023-10-15T12:19:34.043356Z"
    },
    "papermill": {
     "duration": 0.012617,
     "end_time": "2023-10-15T12:19:34.046113",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.033496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9 coat med + 8 v2s + 4 coat small + 3 v2s + 1 coat med "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2854618",
   "metadata": {
    "papermill": {
     "duration": 0.004383,
     "end_time": "2023-10-15T12:19:34.055589",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.051206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a63832",
   "metadata": {
    "papermill": {
     "duration": 0.004557,
     "end_time": "2023-10-15T12:19:34.064706",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.060149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b8b1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:34.075644Z",
     "iopub.status.busy": "2023-10-15T12:19:34.075401Z",
     "iopub.status.idle": "2023-10-15T12:19:34.086582Z",
     "shell.execute_reply": "2023-10-15T12:19:34.085820Z"
    },
    "papermill": {
     "duration": 0.018696,
     "end_time": "2023-10-15T12:19:34.088216",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.069520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "PATIENT_TO_PREDICTION_THEO = np.load('/kaggle/working/PATIENT_TO_PREDICTION_THEO_rank0.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION_THEO_rank1 = np.load('/kaggle/working/PATIENT_TO_PREDICTION_THEO_rank1.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION_THEO.update(PATIENT_TO_PREDICTION_THEO_rank1)\n",
    "\n",
    "PATIENT_TO_PREDICTION = np.load('/kaggle/working/PATIENT_TO_PREDICTION_rank0.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION_rank1 = np.load('/kaggle/working/PATIENT_TO_PREDICTION_rank1.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION.update(PATIENT_TO_PREDICTION_rank1)\n",
    "\n",
    "PATIENT_TO_PREDICTION2 = np.load('/kaggle/working/PATIENT_TO_PREDICTION2_rank0.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION2_rank1 = np.load('/kaggle/working/PATIENT_TO_PREDICTION2_rank1.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION2.update(PATIENT_TO_PREDICTION2_rank1)\n",
    "\n",
    "PATIENT_TO_PREDICTION4 = np.load('/kaggle/working/PATIENT_TO_PREDICTION4_rank0.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION4_rank1 = np.load('/kaggle/working/PATIENT_TO_PREDICTION4_rank1.npy', allow_pickle=True).item()\n",
    "PATIENT_TO_PREDICTION4.update(PATIENT_TO_PREDICTION4_rank1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e7d4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:34.099298Z",
     "iopub.status.busy": "2023-10-15T12:19:34.099035Z",
     "iopub.status.idle": "2023-10-15T12:19:34.111962Z",
     "shell.execute_reply": "2023-10-15T12:19:34.111056Z"
    },
    "papermill": {
     "duration": 0.020504,
     "end_time": "2023-10-15T12:19:34.113866",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.093362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FINAL_SUB = {'patient_id': [], 'bowel_healthy': [], 'bowel_injury': [], \n",
    "             'extravasation_healthy': [], 'extravasation_injury': [], \n",
    "             'kidney_healthy': [], 'kidney_low': [], 'kidney_high': [],\n",
    "             'liver_healthy': [], 'liver_low': [], 'liver_high': [],\n",
    "             'spleen_healthy': [], 'spleen_low': [], 'spleen_high': [],}\n",
    "\n",
    "for patient in PATIENT_TO_PREDICTION:\n",
    "    prediction = PATIENT_TO_PREDICTION[patient].copy()\n",
    "    prediction2 = PATIENT_TO_PREDICTION2[patient].copy()\n",
    "    prediction3 = PATIENT_TO_PREDICTION_THEO[patient].copy()\n",
    "    prediction4 = PATIENT_TO_PREDICTION4[patient].copy()\n",
    "    \n",
    "    #ensemble organ model\n",
    "    #prediction = (prediction + prediction3) / 2\n",
    "    prediction = (prediction * 0.5) + (prediction3 * 0.5)\n",
    "    \n",
    "    #bowel avg from extrav-bowel\n",
    "    prediction[9] = (prediction[9] * 0.7) + (prediction4[1] * 0.15) + (prediction2[1]*0.15)\n",
    "    \n",
    "    #ensemble extrav\n",
    "    prediction2[0] = (prediction2[0] + prediction4[0]) / 2\n",
    "#     prediction2[0] = prediction4[0]\n",
    "    \n",
    "    \n",
    "    #prediction = prediction3\n",
    "    \n",
    "    FINAL_SUB['patient_id'].append(patient)\n",
    "\n",
    "    #FINAL_SUB['bowel_healthy'].append(0.9796631712742294)\n",
    "    #FINAL_SUB['bowel_injury'].append(0.040673657451541154)\n",
    "\n",
    "    #FINAL_SUB['bowel_healthy'].append(1 - prediction[9])\n",
    "    #FINAL_SUB['bowel_injury'].append(prediction[9] * 2)\n",
    "\n",
    "    #FINAL_SUB['bowel_injury'] = prediction[9]*0.9 + 0.020336828725770577*0.1\n",
    "    #FINAL_SUB['bowel_healthy'] = (1 - prediction[9])*0.9 + 0.9796631712742294*0.1\n",
    "    \n",
    "#     bowel_w = 2\n",
    "#     extrav_w = 6\n",
    "#     low_w = 2\n",
    "#     high_w = 4\n",
    "    \n",
    "    bowel_w = 1.75\n",
    "    extrav_w = 8\n",
    "    low_w = 1.75\n",
    "    high_w = 3.5\n",
    "    \n",
    "    FINAL_SUB['bowel_healthy'].append(1 - prediction[9])\n",
    "    FINAL_SUB['bowel_injury'].append(prediction[9] * bowel_w)\n",
    "    #FINAL_SUB['bowel_injury'].append(prediction[9])\n",
    "    \n",
    "#     FINAL_SUB['extravasation_healthy'].append(0.936447410231967*0.5 + (1-prediction2[0])*0.5)\n",
    "#     FINAL_SUB['extravasation_injury'].append( (0.3813155386081983*0.5 + prediction2[0]*extrav_w) + prediction[9]) #the trick is extrav is better with extrav+bowel\n",
    "    \n",
    "    FINAL_SUB['extravasation_healthy'].append(1 - prediction2[0])\n",
    "    FINAL_SUB['extravasation_injury'].append(0.06355258976803305 + (prediction2[0] * extrav_w))\n",
    "    \n",
    "#     FINAL_SUB['extravasation_healthy'].append(0.936447410231967*0.5 + (1-prediction2[0])*0.5)\n",
    "#     FINAL_SUB['extravasation_injury'].append( (0.3813155386081983*0.5 + prediction2[0]*extrav_w)) #the trick is extrav is better with extrav+bowel\n",
    "    \n",
    "    \n",
    "    FINAL_SUB['liver_healthy'].append(1 - prediction[0])\n",
    "    FINAL_SUB['liver_low'].append(prediction[3]*low_w)\n",
    "    FINAL_SUB['liver_high'].append(prediction[4]*high_w)\n",
    "\n",
    "    #valid_study_level_pred['kidney_healthy'] = valid_study_level['kidney_healthy'].mean()\n",
    "    #valid_study_level_pred['kidney_low'] = valid_study_level['kidney_low'].mean()\n",
    "    #valid_study_level_pred['kidney_high'] = valid_study_level['kidney_high'].mean()\n",
    "\n",
    "    FINAL_SUB['spleen_healthy'].append(1 - prediction[1])\n",
    "    FINAL_SUB['spleen_low'].append(prediction[5]*low_w)\n",
    "    FINAL_SUB['spleen_high'].append(prediction[6]*high_w)\n",
    "\n",
    "    FINAL_SUB['kidney_healthy'].append(1 - prediction[2])\n",
    "    FINAL_SUB['kidney_low'].append((prediction[7])*low_w)\n",
    "    FINAL_SUB['kidney_high'].append(prediction[8]*high_w)\n",
    "\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a34912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:34.125597Z",
     "iopub.status.busy": "2023-10-15T12:19:34.124844Z",
     "iopub.status.idle": "2023-10-15T12:19:34.946429Z",
     "shell.execute_reply": "2023-10-15T12:19:34.945406Z"
    },
    "papermill": {
     "duration": 0.829422,
     "end_time": "2023-10-15T12:19:34.948395",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.118973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26501</td>\n",
       "      <td>0.997718</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.998705</td>\n",
       "      <td>0.073914</td>\n",
       "      <td>0.993237</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.992961</td>\n",
       "      <td>0.016052</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10051</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.992387</td>\n",
       "      <td>0.124455</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.981912</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.379380</td>\n",
       "      <td>0.946607</td>\n",
       "      <td>0.330375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0      26501       0.997718      0.003993               0.998705   \n",
       "1      10051       0.994993      0.008763               0.992387   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.073914        0.993237    0.013022     0.002546   \n",
       "1              0.124455        0.989373    0.015757     0.006582   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.983368   0.027066    0.005253        0.992961    0.016052   \n",
       "1       0.981912   0.029391    0.004002        0.379380    0.946607   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.001973  \n",
       "1     0.330375  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = pd.DataFrame(FINAL_SUB)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7f9f8",
   "metadata": {
    "papermill": {
     "duration": 0.00536,
     "end_time": "2023-10-15T12:19:34.959666",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.954306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6adf702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:34.970694Z",
     "iopub.status.busy": "2023-10-15T12:19:34.970293Z",
     "iopub.status.idle": "2023-10-15T12:19:36.019307Z",
     "shell.execute_reply": "2023-10-15T12:19:36.017940Z"
    },
    "papermill": {
     "duration": 1.057824,
     "end_time": "2023-10-15T12:19:36.022348",
     "exception": false,
     "start_time": "2023-10-15T12:19:34.964524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a823f",
   "metadata": {
    "papermill": {
     "duration": 0.008399,
     "end_time": "2023-10-15T12:19:36.040863",
     "exception": false,
     "start_time": "2023-10-15T12:19:36.032464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ba0d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T12:19:36.060834Z",
     "iopub.status.busy": "2023-10-15T12:19:36.060466Z",
     "iopub.status.idle": "2023-10-15T12:19:36.077967Z",
     "shell.execute_reply": "2023-10-15T12:19:36.077016Z"
    },
    "papermill": {
     "duration": 0.03007,
     "end_time": "2023-10-15T12:19:36.080563",
     "exception": false,
     "start_time": "2023-10-15T12:19:36.050493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374e69a",
   "metadata": {
    "papermill": {
     "duration": 0.00932,
     "end_time": "2023-10-15T12:19:36.099770",
     "exception": false,
     "start_time": "2023-10-15T12:19:36.090450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8de7c",
   "metadata": {
    "papermill": {
     "duration": 0.009408,
     "end_time": "2023-10-15T12:19:36.118624",
     "exception": false,
     "start_time": "2023-10-15T12:19:36.109216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3475b58",
   "metadata": {
    "papermill": {
     "duration": 0.010887,
     "end_time": "2023-10-15T12:19:36.145253",
     "exception": false,
     "start_time": "2023-10-15T12:19:36.134366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.460761,
   "end_time": "2023-10-15T12:19:36.579255",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-15T12:14:55.118494",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
